{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT4SOUwR2e8B",
        "outputId": "47f56c62-c9b6-443e-eda8-e0eb653f1d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Number of rows after removing null values: 1773\n",
            "age                                                                                                                                                                   object\n",
            "gender                                                                                                                                                                object\n",
            "university                                                                                                                                                            object\n",
            "department                                                                                                                                                            object\n",
            "academic_year                                                                                                                                                         object\n",
            "current_cgpa                                                                                                                                                         float64\n",
            "did_you_receive_a_waiver_or_scholarship_at_your_university?                                                                                                           object\n",
            "in_a_semester,_how_often_have_you_had_little_interest_or_pleasure_in_doing_things?                                                                                     int64\n",
            "in_a_semester,_how_often_have_you_been_feeling_down,_depressed_or_hopeless?                                                                                            int64\n",
            "in_a_semester,_how_often_have_you_had_trouble_falling_or_staying_asleep,_or_sleeping_too_much?                                                                         int64\n",
            "in_a_semester,_how_often_have_you_been_feeling_tired_or_having_little_energy?                                                                                          int64\n",
            "in_a_semester,_how_often_have_you_had_poor_appetite_or_overeating?                                                                                                     int64\n",
            "in_a_semester,_how_often_have_you_been_feeling_bad_about_yourself_-_or_that_you_are_a_failure_or_have_let_yourself_or_your_family_down?                                int64\n",
            "in_a_semester,_how_often_have_you_been_having_trouble_concentrating_on_things,_such_as_reading_the_books_or_watching_television?                                       int64\n",
            "in_a_semester,_how_often_have_you_moved_or_spoke_too_slowly_for_other_people_to_notice?_or_you've_been_moving_a_lot_more_than_usual_because_you've_been_restless?      int64\n",
            "in_a_semester,_how_often_have_you_had_thoughts_that_you_would_be_better_off_dead,_or_of_hurting_yourself?                                                              int64\n",
            "depression_value                                                                                                                                                       int64\n",
            "depression_label                                                                                                                                                      object\n",
            "dtype: object\n",
            "age                                                                                                                                                                    int64\n",
            "gender                                                                                                                                                                 int64\n",
            "university                                                                                                                                                             int64\n",
            "department                                                                                                                                                             int64\n",
            "academic_year                                                                                                                                                          int64\n",
            "current_cgpa                                                                                                                                                         float64\n",
            "did_you_receive_a_waiver_or_scholarship_at_your_university?                                                                                                            int64\n",
            "in_a_semester,_how_often_have_you_had_little_interest_or_pleasure_in_doing_things?                                                                                     int64\n",
            "in_a_semester,_how_often_have_you_been_feeling_down,_depressed_or_hopeless?                                                                                            int64\n",
            "in_a_semester,_how_often_have_you_had_trouble_falling_or_staying_asleep,_or_sleeping_too_much?                                                                         int64\n",
            "in_a_semester,_how_often_have_you_been_feeling_tired_or_having_little_energy?                                                                                          int64\n",
            "in_a_semester,_how_often_have_you_had_poor_appetite_or_overeating?                                                                                                     int64\n",
            "in_a_semester,_how_often_have_you_been_feeling_bad_about_yourself_-_or_that_you_are_a_failure_or_have_let_yourself_or_your_family_down?                                int64\n",
            "in_a_semester,_how_often_have_you_been_having_trouble_concentrating_on_things,_such_as_reading_the_books_or_watching_television?                                       int64\n",
            "in_a_semester,_how_often_have_you_moved_or_spoke_too_slowly_for_other_people_to_notice?_or_you've_been_moving_a_lot_more_than_usual_because_you've_been_restless?      int64\n",
            "in_a_semester,_how_often_have_you_had_thoughts_that_you_would_be_better_off_dead,_or_of_hurting_yourself?                                                              int64\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-6b688a524f5f>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n",
            "<ipython-input-1-6b688a524f5f>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n",
            "<ipython-input-1-6b688a524f5f>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n",
            "<ipython-input-1-6b688a524f5f>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n",
            "<ipython-input-1-6b688a524f5f>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n",
            "<ipython-input-1-6b688a524f5f>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Stacking Model ---\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "             Mild Depression       0.89      1.00      0.94        68\n",
            "          Minimal Depression       1.00      0.60      0.75        15\n",
            "         Moderate Depression       0.99      0.94      0.96        80\n",
            "Moderately Severe Depression       0.96      0.96      0.96        97\n",
            "               No Depression       1.00      1.00      1.00         6\n",
            "           Severe Depression       0.97      0.99      0.98        89\n",
            "\n",
            "                    accuracy                           0.95       355\n",
            "                   macro avg       0.97      0.91      0.93       355\n",
            "                weighted avg       0.96      0.95      0.95       355\n",
            "\n",
            "Accuracy: 0.9549295774647887\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Depression_for_Comparision(PHQ_9).csv')\n",
        "\n",
        "# Clean column names by removing leading numbers and spaces\n",
        "data.columns = data.columns.str.replace(r'^\\d+\\.\\s*', '', regex=True).str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Function to convert CGPA range to float (mean of the range)\n",
        "def convert_cgpa(cgpa):\n",
        "    if isinstance(cgpa, str) and '-' in cgpa:\n",
        "        parts = cgpa.split('-')\n",
        "        return (float(parts[0].strip()) + float(parts[1].strip())) / 2\n",
        "    try:\n",
        "        return float(cgpa)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "# Apply the conversion function to the current_cgpa column\n",
        "data['current_cgpa'] = data['current_cgpa'].apply(convert_cgpa)\n",
        "\n",
        "# Drop rows with any null values\n",
        "data_cleaned = data.dropna()\n",
        "\n",
        "# Display the number of rows remaining after removing null values\n",
        "remaining_data_count = data_cleaned.shape[0]\n",
        "print(f\"Number of rows after removing null values: {remaining_data_count}\")\n",
        "\n",
        "# Check data types of the columns\n",
        "print(data_cleaned.dtypes)\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = ['age', 'gender', 'university', 'department', 'academic_year',\n",
        "                       'did_you_receive_a_waiver_or_scholarship_at_your_university?']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    data_cleaned[col] = label_encoder.fit_transform(data_cleaned[col])\n",
        "\n",
        "# Select features and target variable\n",
        "X = data_cleaned.drop(columns=['depression_label', 'depression_value'])  # Features\n",
        "y = data_cleaned['depression_label']  # Target variable\n",
        "\n",
        "# Check for any non-numeric columns before train-test split\n",
        "print(X.dtypes)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling (for SVM and KNN)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define base models for stacking\n",
        "base_estimators = [\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('SVM', SVC(probability=True)),\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Naive Bayes', GaussianNB())\n",
        "]\n",
        "\n",
        "# Create a stacking classifier\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=base_estimators,\n",
        "    final_estimator=MLPClassifier(max_iter=1000)\n",
        ")\n",
        "\n",
        "# Train the stacking model\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "\n",
        "# Display the classification report for the stacking model\n",
        "print(\"--- Stacking Model ---\")\n",
        "print(classification_report(y_test, y_pred_stacking))\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred_stacking)}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEvn1UTN24xh",
        "outputId": "1be92241-b077-4a38-c23f-a1324d556530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Depression_for_C_2.csv')\n",
        "\n",
        "# Clean column names by removing leading numbers and spaces\n",
        "data.columns = data.columns.str.replace(r'^\\d+\\.\\s*', '', regex=True).str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Select only PHQ-1 to Depression Label columns\n",
        "columns_to_consider = ['phq-1', 'phq-2', 'phq-3', 'phq-4', 'phq-5', 'phq-6', 'phq-7', 'phq-8', 'phq-9', 'depression_value', 'depression_label']\n",
        "data_depression = data[columns_to_consider]\n",
        "\n",
        "# Check unique values in the depression_label column\n",
        "print(\"Unique values in 'depression_label' before mapping:\", data_depression['depression_label'].unique())\n",
        "\n",
        "# Drop rows with any null values\n",
        "data_cleaned = data_depression.dropna()\n",
        "\n",
        "# Encode the target variable with additional unique labels\n",
        "# Updated mapping dictionary\n",
        "mapping_dict = {\n",
        "    'No Depression': 0,\n",
        "    'Minimal Depression': 1,\n",
        "    'Mild Depression': 2,\n",
        "    'Moderate Depression': 3,\n",
        "    'Moderately Severe Depression': 4,\n",
        "    'Severe Depression': 5\n",
        "}\n",
        "\n",
        "# Map the depression labels\n",
        "data_cleaned['depression_label'] = data_cleaned['depression_label'].map(mapping_dict)\n",
        "\n",
        "# Check for NaN values in the target variable after mapping\n",
        "if data_cleaned['depression_label'].isnull().any():\n",
        "    print(\"There are NaN values in the target variable after mapping.\")\n",
        "    print(data_cleaned['depression_label'].isnull().sum(), \"rows have NaN in 'depression_label'.\")\n",
        "    data_cleaned = data_cleaned.dropna(subset=['depression_label'])\n",
        "\n",
        "# Define features and target variable\n",
        "X = data_cleaned.drop(columns=['depression_label'])  # Features\n",
        "y = data_cleaned['depression_label']  # Target variable\n",
        "\n",
        "# Check number of unique classes in y again\n",
        "print(\"Number of unique classes in target variable:\", y.nunique())\n",
        "\n",
        "# Proceed if there are at least two unique classes\n",
        "if y.nunique() < 2:\n",
        "    print(\"Insufficient classes for training.\")\n",
        "else:\n",
        "    # Continue with the rest of the code...\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scale features (for SVM, KNN, and MLP)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Define the base estimators\n",
        "    base_estimators = [\n",
        "        ('Random Forest', RandomForestClassifier(random_state=42)),\n",
        "        ('SVM', SVC(probability=True, random_state=42)),\n",
        "        ('KNN', KNeighborsClassifier()),\n",
        "        ('Naive Bayes', GaussianNB())\n",
        "    ]\n",
        "\n",
        "    # Define the stacking classifier with MLP as the meta model\n",
        "    stacking_model = StackingClassifier(\n",
        "        estimators=base_estimators,\n",
        "        final_estimator=MLPClassifier(max_iter=1000, random_state=42)\n",
        "    )\n",
        "\n",
        "    # Train the stacking model\n",
        "    stacking_model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_stacking = stacking_model.predict(X_test)\n",
        "\n",
        "    # Display the classification report\n",
        "    print(\"--- Stacking Model ---\")\n",
        "    print(classification_report(y_test, y_pred_stacking))\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_stacking):.4f}\\n\")\n",
        "\n",
        "    # Calculate and display specificity for each class in the stacking model\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_stacking)\n",
        "    specificities = []\n",
        "    for i in range(len(conf_matrix)):\n",
        "        tn = np.sum(np.delete(np.delete(conf_matrix, i, axis=0), i, axis=1))\n",
        "        fp = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        specificities.append(specificity)\n",
        "\n",
        "    print(f\"Specificity for each class in stacking model: {specificities}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdaKPocM36z4",
        "outputId": "0c59cc77-9b7a-497b-85d1-3bbce4b12f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'depression_label' before mapping: ['Moderate Depression' 'Mild Depression' 'Moderately Severe Depression'\n",
            " 'Minimal Depression' 'Severe Depression' 'No Depression']\n",
            "Number of unique classes in target variable: 6\n",
            "--- Stacking Model ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         9\n",
            "           1       1.00      0.88      0.93        16\n",
            "           2       0.97      1.00      0.99        71\n",
            "           3       1.00      1.00      1.00        95\n",
            "           4       1.00      1.00      1.00       112\n",
            "           5       1.00      1.00      1.00        93\n",
            "\n",
            "    accuracy                           0.99       396\n",
            "   macro avg       1.00      0.98      0.99       396\n",
            "weighted avg       1.00      0.99      0.99       396\n",
            "\n",
            "Accuracy: 0.9949\n",
            "\n",
            "Specificity for each class in stacking model: [1.0, 1.0, 0.9938461538461538, 1.0, 1.0, 1.0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANXIETY"
      ],
      "metadata": {
        "id": "SXVARfr07Y2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Anxiety_for_Comparision(GAD-7).csv')\n",
        "\n",
        "# Clean column names\n",
        "data.columns = data.columns.str.replace(r'^\\d+\\.\\s*', '', regex=True).str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = [\n",
        "    'age', 'gender', 'university', 'department', 'academic_year', 'current_cgpa',\n",
        "    'in_a_semester,_how_often_you_felt_nervous,_anxious_or_on_edge_due_to_academic_pressure?',\n",
        "    'in_a_semester,_how_often_have_you_been_unable_to_stop_worrying_about_your_academic_affairs?',\n",
        "    'in_a_semester,_how_often_have_you_had_trouble_relaxing_due_to_academic_pressure?',\n",
        "    'in_a_semester,_how_often_have_you_been_easily_annoyed_or_irritated_because_of_academic_pressure?',\n",
        "    'in_a_semester,_how_often_have_you_worried_too_much_about_academic_affairs?',\n",
        "    'in_a_semester,_how_often_have_you_been_so_restless_due_to_academic_pressure_that_it_is_hard_to_sit_still?',\n",
        "    'in_a_semester,_how_often_have_you_felt_afraid,_as_if_something_awful_might_happen?'\n",
        "]\n",
        "target = 'anxiety_label'\n",
        "\n",
        "# Drop rows with any null values in features or target\n",
        "data_cleaned = data.dropna(subset=features + [target])\n",
        "\n",
        "# Define features and target variable\n",
        "X = data_cleaned[features]\n",
        "y = data_cleaned[target]\n",
        "\n",
        "# Encode categorical features if needed\n",
        "X = pd.get_dummies(X, drop_first=True)  # One-hot encoding for categorical variables\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
        "    ('SVM', SVC(probability=True, random_state=42)),\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Naive Bayes', GaussianNB()),\n",
        "    ('MLP', MLPClassifier(max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "# Stacking Classifier\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=RandomForestClassifier(random_state=42))\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "\n",
        "# Display the classification report\n",
        "print(\"--- Stacking Model ---\")\n",
        "print(classification_report(y_test, y_pred_stacking))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_stacking):.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqSF6moV7E0B",
        "outputId": "47d6cb62-e772-41ad-dcad-ce871b5c484c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- Stacking Model ---\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    Mild Anxiety       0.97      0.98      0.98       100\n",
            " Minimal Anxiety       0.94      0.91      0.92        33\n",
            "Moderate Anxiety       1.00      0.97      0.99       120\n",
            "  Severe Anxiety       0.98      1.00      0.99       153\n",
            "\n",
            "        accuracy                           0.98       406\n",
            "       macro avg       0.97      0.97      0.97       406\n",
            "    weighted avg       0.98      0.98      0.98       406\n",
            "\n",
            "Accuracy: 0.9803\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Depression_for_C_2.csv')\n",
        "\n",
        "# Clean column names by removing leading numbers and spaces\n",
        "data.columns = data.columns.str.replace(r'^\\d+\\.\\s*', '', regex=True).str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Convert CGPA range to float (mean of the range)\n",
        "def convert_cgpa(cgpa):\n",
        "    if isinstance(cgpa, str) and '-' in cgpa:\n",
        "        parts = cgpa.split('-')\n",
        "        return (float(parts[0].strip()) + float(parts[1].strip())) / 2\n",
        "    try:\n",
        "        return float(cgpa)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "# Apply the conversion function to the 'current_cgpa' column\n",
        "data['current_cgpa'] = data['current_cgpa'].apply(convert_cgpa)\n",
        "\n",
        "# Handle any NaN values in 'current_cgpa' and 'anxiety_label'\n",
        "data.dropna(subset=['current_cgpa', 'anxiety_label'], inplace=True)\n",
        "\n",
        "# Select only the GAD-1 to anxiety_label columns\n",
        "features = ['gad-1', 'gad-2', 'gad-3', 'gad-4', 'gad-5', 'gad-6', 'gad-7']\n",
        "if 'anxiety_label' in data.columns:\n",
        "    features.append('anxiety_label')\n",
        "\n",
        "# Ensure all required columns are in the dataset\n",
        "if not all(col in data.columns for col in features):\n",
        "    raise ValueError(\"One or more required columns are missing from the dataset.\")\n",
        "\n",
        "X = data[features[:-1]]  # Features (GAD-1 to GAD-7)\n",
        "y = data['anxiety_label']  # Target variable\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('SVM', SVC(probability=True)),  # Enable probability estimates for stacking\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Naive Bayes', GaussianNB()),\n",
        "    ('MLP', MLPClassifier(max_iter=1000))\n",
        "]\n",
        "\n",
        "# Stacking Classifier\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=RandomForestClassifier())\n",
        "stacking_model.fit(X_train, y_train)\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "\n",
        "print('--- Stacking Classifier Classification Report ---')\n",
        "print(classification_report(y_test, y_pred_stacking))\n",
        "print(f'Stacking Classifier Accuracy: {accuracy_score(y_test, y_pred_stacking)}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx_OlMI46lWR",
        "outputId": "f41b48fa-b5d9-4986-c739-c30e97524a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- Stacking Classifier Classification Report ---\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    Mild Anxiety       1.00      1.00      1.00        96\n",
            " Minimal Anxiety       1.00      1.00      1.00        29\n",
            "Moderate Anxiety       1.00      1.00      1.00       105\n",
            "  Severe Anxiety       1.00      1.00      1.00       116\n",
            "\n",
            "        accuracy                           1.00       346\n",
            "       macro avg       1.00      1.00      1.00       346\n",
            "    weighted avg       1.00      1.00      1.00       346\n",
            "\n",
            "Stacking Classifier Accuracy: 1.0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}